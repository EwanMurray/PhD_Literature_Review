---
title: "How does procedural complexity affect the efficacy of spaced retrieval practice?"
shorttitle: "Literature Review for TAP Progression Meeting"
author:

  - name: Ewan Murray
    affiliation   : 
    - name   : University of York
    department: Department of Psychology
    address: Heslington
    city: York
    region: North Yorkshire
    postal-code: YO10 5DD
    corresponding: true
   # orcid: 0000-0000-0000-0001
    email: ewan.murray@york.ac.uk
    # roles:
    #   - conceptualization
    #   - writing
        
  - name: Aidan J. Horner
    #orcid: 0000-0000-0000-0002
    affiliation   : 
    - name   : University of York
    
  - name          : Silke M. Göbel
    affiliation   : 
    - name   : University of York
    - name   : University of Oslo
    #orcid: 0000-0000-0000-0003
abstract: "This document is a template."
keywords: [keyword1, keyword2, keyword3]
bibliography: bibliography.bib
format:
  apaquarto-docx: default
  apaquarto-html: default
  apaquarto-pdf:
    documentmode: man
---

VERY SIMILAR TO START OF EXP1/2

Recent advice on best practice in education has focused on the long-term retention of key mathematical knowledge [@ofsted2021]. One reason for this is that the majority of mathematics learning builds directly on previous ideas. Ideas which could have been taught days, months, or years previously. Unfortunately, students often struggle to retrieve this knowledge[@karpicke2012]. Learners' inability to retrieve past material requires instructors to allocate additional time to reintroduce it. This impedes not only their own learning, but, in the case of classroom learning, others. Time is a scarce resource in educational settings, making this an important problem to remedy. Fortunately, there are promising interventions that require little additional time and resources: distributing practice and promoting active retrieval. These two interventions employ the spacing effect and testing effect, respectively. The spacing effect describes the difference in retention when practice is distributed over two or more practice sessions over time, rather than in one massed session. While the testing effect describes the change in retention when material is actively retrieved rather than restudied. In combination, they form spaced retrieval practice [@hopkins2016]. Already, spaced retrieval practice is in regular use by many students in the United Kingdom. Online Platforms such as [@arceducation] and [@sparxma] claim to harness the spacing and testing effect to improve retention for pupils. In particular, @sparxma states that they "ensure the practice uses spaced repetition and interleaving to support a change in students' long-term memories" and their software is "is proven by The University of Cambridge to significantly boost grades". This is in reference to a technical report commissioned by Sparx and implemented by RAND Europe and the University of Cambridge [@brown2021]. They found that greater time spent on the Sparx Maths platform is positively and significantly associated with higher outcomes in maths. However, there is still limited research into the efficacy of these programmes with no peer-reviewed studies investigating their use of spacing [@gidaropoulos2021]. With sites such as Sparx Maths being in use by more than 2 million students in more than 2,200 schools [@sparxma], a small positive effect in retention could have a large impact. Furthermore, there is increasing push to bring these effects into everyday classroom use. A recent report by the British government suggests frequent, low-stakes testing as an essential strategy [@ofsted2021]. Understanding when, how and what factors moderate the use of spaced retrieval, before widespread use, is essential.

This review has two purposes. Firstly, to review the existing evidence for spaced retrieval practice for mathematics and, secondly, to explore what factors moderate the effectiveness of spaced retrieval practice in mathematics learning. The evidence for the spacing and testing effect generally will be discussed, and different theoretical accounts will be described and evaluated, followed by a potential problem with investigating retrieval in mathematics. Next, the evidence of the effectiveness of the combination of spacing and testing (spaced retrieval practice) in mathematics will be reviewed along with proposed moderators of its effectiveness. Subsequently, there will be a discussion of complexity, why it is important and how it is defined in relation to mathematical content. Following these definitions, the potential effects complexity may have on the efficacy of spaced retrieval practice, and how it may interact with the different accounts of the underlying mechanisms of spacing and testing effects will be explored. Finally, we explain how the current literature motivated our hypotheses.

# Spacing effect and distributed practice

This section will briefly outline the history of the spacing effect, and how the effect has been studied across domains, before returning to mathematics later. Multiple phrases are used in the literature to describe the difference in retention (i.e., performance on a delayed post-test) when practice is spaced over multiple sessions. The spacing effect refers to the observed change in retention when learning is spaced over multiple sessions over time, rather than massed into a single session [@delaney2010]. The lag effect is the change in retention when two different spacing routines are compared [@küpper-tetzel2014]. Distributed practice is often used as an umbrella term for interventions that utilise the spacing or lag effects [@benjamin2010]. A meta-meta-analysis undertaken by @hattie2008visible into many educational interventions found spaced versus massed practice to be one of the most effective interventions. They found an effect of d = 0.71, using two meta-analyses containing 63 studies and 5,028 participants. As an example of what a Cohen’s d = 0.7 effect suggests, if a study which claimed to raise IQ (where the mean is 100 and standard deviation is 15) then a 0.7 effect size would mean a 10.5 point increase in IQ. The study of the spacing effect began in parallel with the advent of experimental psychology. @ebbinghaus1964 Ebbinghaus (1885/1913), for example, memorised nonsense syllables and plotted forgetting curves, finding that memories decay exponentially (i.e., quickly at first and then slower). Importantly, this rate of decay slows down after subsequent recall/ retrieval (see figure 1); these results have been replicated successfully [@murre2015]. The spacing effect has been the subject of hundreds of experiments [@cepeda2006; @hattie2008visible], proving to be a robust effect found across age groups, tasks, and species [@walsh2018]. Most prior experiments into the spacing effect have investigated learning verbal material[@delaney2010, provides a critical review].

Figure 1 Forgetting curve showing the change in reftrieval strength as a function of time Note. Retrieval strength signifies how easily the item can be retrieved from long term memory. The thick vertical line represents a post-test. The dashed vertical lines signify retrieval events, the faded red dashed lines show how the memory would have continued to decay without the retrieval events.

Spacing effect experiments can be run run within or across-session [@küpper-tetzel2014]. Where within-session experiments look at the temporal spacing of stimuli within a single session and across-session experiments look at the spacing of practice across multiple sessions. Within mathematics there is very little work done on within-session spacing [exceptions being: @foster2019; @rea1985], while this is much more common within other domains such as verbal learning [@delaney2010]. Therefore, this review will focus on across-session spacing experiments. In the most basic across-session spacing effect experiment (see figure 2), retention on a post test is compared against two practice conditions: practice is either massed into one session or distributed over two sessions. This involves two key design decisions: the inter-session interval, i.e., the time between the initial and subsequent learning sessions, and the retrieval interval, i.e., the time from the final learning session to the post test. The amount and type of practice are kept constant, therefore, subject to adequate randomization, the only difference between the two conditions is the temporal spacing.

Figure 2

Simple spacing paradigm A picture containing text, screenshot, diagram, rectangle

A simple spacing experiment design consisting of a massed condition where all practice is undertaken in one session and a spaced condition where practice is split into two sessions with an inter-session interval between the first and second learning events. Both conditions are followed by a delayed test.

The optimum inter-session interval is linked to the length of the required retrieval interval. One large-scale online study (n = 1,350) taught participants 32 obscure facts [@cepeda2008]. They varied the inter-session interval from 7 to 105 days and the retrieval interval from 7 to 350 days. They found that the optimum inter-session interval depended on the retrieval interval required. For example, to be able to recall a fact 35 days later they found it was best to wait 8 days after initial learning to retrieve it, but to recall a fact 350 days later the optimum inter-session interval was 27 days [@cepeda2008]. This relationship between the inter-session interval and the retrieval interval has been named the Glenberg surface [@delaney2010]. It refers specifically to the non-monotonic relationship between the length of the inter-session interval and of the retrieval interval: increasing the inter-session interval increases retention up to a point after which retention begins to fall again. This means there is no one “optimum” spacing schedule, but rather depends on for how long the learner is required to remember an item. More complex spacing schedules are possible with more than two sessions. In this case key design features are the number of sessions and whether these sessions are uniformly spaced or expanding. This was an interesting question to ask as initial short gaps boost the chance of a successful retrieval, which strengthens the memory allowing for a greater chance or retrieval after the next longer gap [@rea1985]. And secondly, increasing the gaps should increase the difficulty of retrieval, and more effort should result in greater gains in retrieval strength [@bjork2011]. However, a recent meta-analysis looking at spaced retrieval practice found no significant difference between expanding and uniform designs [@latimier2021]. On the other hand if the two schedules offer equal benefit, then expanding schedules are more time efficient. As expanding schedules produce the same gain in retention over the same period of time with fewer practice sessions. Alongside increased retention, spacing also improves students’ and teachers ability to accurately gauge students’ learning. When year 7 students were asked to predict their scores on a post-test, after completing either a massed or spaced practice routine, spaced practice increased both the scores of the pupils and the accuracy of their predictions [@emeny2021], while those on the massed schedule were overconfident. @emeny2021 suggest the overconfidence may have arisen because massed practice led to greater fluency within the session, however this performance did not lead to greater long term learning.

Description automatically generated Note. A simple spacing experiment design consisting of a massed condition where all practice is undertaken in one session and a spaced condition where practice is split into two sessions with an inter-session interval between the first and second learning events. Both conditions are followed by a delayed test. The optimum inter-session interval is linked to the length of the required retrieval interval.

One large-scale online study (n = 1,350) taught participants 32 obscure facts [@cepeda2008]. They varied the inter-session interval from 7 to 105 days and the retrieval interval from 7 to 350 days to optimally schedule the learning of facts. They found that the optimum inter-session interval depended on the retrieval interval required. For example, to be able to recall a fact 35 days later they found it was best to wait 8 days after initial learning to retrieve it, but to recall a fact 350 days later the optimum inter-session interval was 27 days [@cepeda2008]. This relationship between the inter-session interval and the retrieval interval has been named the Glenberg surface [@delaney2010]. It refers specifically to the non-monotonic relationship between the length of the inter-session interval and of the retrieval interval: increasing the inter-session interval increases retention up to a point after which retention begins to fall again. This means there is no one “optimum” spacing schedule, but rather depends on for how long the learner is required to remember an item. More complex spacing schedules are possible with more than two sessions. In this case key design features are the number of sessions and whether these sessions are uniformly spaced or expanding. This was an interesting question to ask as initial short gaps boost the chance of a successful retrieval, which strengthens the memory allowing for a greater chance or retrieval after the next longer gap [@rea1985]. And secondly, increasing the gaps should increase the difficulty of retrieval, and more effort should result in greater gains in retrieval strength [@bjork2011]. However, a recent meta-analysis looking at spaced retrieval practice found no significant difference between expanding and uniform designs [@latimier2021]. On the other hand if the two schedules offer equal benefit, then expanding schedules are more time efficient. As expanding schedules produce the same gain in retention over the same period of time with fewer practice sessions. Alongside increased retention, spacing also improves students’ and teachers ability to accurately gauge students’ learning. When year 7 students were asked to predict their scores on a post-test, after completing either a massed or spaced practice routine, spaced practice increased both the scores of the pupils and the accuracy of their predictions [@emeny2021]. While those on the massed schedule were overconfident. @emeny2021 suggest the overconfidence may have arisen either because massed practice led to greater fluency within the session, however this performance did not lead to greater long term learning.

## Theories of the spacing effect

Despite the large body of evidence in support of the spacing effect, there is a lack of consensus on the underlying mechanisms [@delaney2010; @dempster1988; @walsh2018]. There are many theories that aim to explain the spacing effect, however, currently no one theory, or simple combination, adequately explains the phenomena [see @delaney2010 for a critical review of within-session verbal learning spacing experiments and @küpper-tetzel2014 for across-session]. The most frequently discussed theories include study-phase retrieval, contextual variability, and deficient processing.

Study-phase retrieval suggests that the memory of a previously studied item is strengthened by the retrieval of the original learning event [@thios1976]. The degree to which study-phase retrieval improves retention is dependent on the difficulty of recall [@küpper-tetzel2014]. The harder the item is to recall, while still being successful, the better for future recall. This is in line with the idea of desirable difficulties, which suggested that there are techniques (e.g., spacing, interleaving, retrieval practice) that make learning harder, to the detriment of performance, but leads to greater long term retention [@bjork2011]. Evidence for this phenomena was found by @magliero1983 when spacing caused increased processing effort (measured by pupil dilation) for word pair learning. When the retrieval interval is too long in a spacing experiment, the probability of successful retrieval is too low and therefore in the study-phase retrieval account, retention for that item is worse. This potentially explains the non-monotonic relationship between inter-session intervals and retrieval intervals. Additional evidence for the study-phase retrieval comes from an experiment showing that participants could judge how far apart two presentations of the same word, but not two differing words [@hintzman1973]. Further support was found by @wahlheim2014, who asked participants to study two word lists. They found that when participants were asked to indicate whether a word was repeated on either the current or the previous list, their future recall ability of these repetitions was enhanced when the word appeared on the previous list compared to when it was repeated within one list.

Another account of the spacing effect is contextual variability [@glenberg1979]. This theory suggests that during the initial (and any subsequent) retrieval, contextual information is automatically encoded alongside the learning material and that this information provides additional access routes to aid retrieval. This additional information may be related to the environment the learning took place in, such as the location or smells while learning or even the learner’s current state of mind [@küpper-tetzel2014]. @küpper-tetzel2014 provides several examples of studies that manipulated the variability of the context between the initial and final retrieval and found they showed no significant increase or even led to a decrease in performance [@dempster1988]. A particularly notable early failure to empirically test this theory was performed by @ross1978. In this experiment participants learnt two lists. One list where an item at position x in a sequence is repeated at position y. A second list where two different items are positioned at x and y. The probability of recalling one of the repeated words, during free recall, would be the same as the probability of recalling one of the two different words. This is because they are at the same position in the list, therefore have the same context. They did not find this to be the case, therefore considered this evidence against the contextual variability theory. However,[@lohnas2011] ran the same analyses on six different previous free recall experimental datasets and found the relationship described above. This provides some empirical evidence for contextual variability. They go on to link contextual variation with the study-phase retrieval hypothesis as it would make sense that during study-phase retrieval the original contextual information and the contextual information from subsequent repetitions are all encoded providing additional retrieval routes.

The deficient processing account of the spacing effect suggests that the phenomenon arises due to learners not processing the material in sufficient depth under the massed condition [@hintzman1974]. Early studies found that during self paced massed practice participants spent less time on material that was previously presented, while they spent longer on spaced items [@shaughnessy1972]. This additional exposure was found in the distributed practice conditions, but didn't fully account for the gains in the distributed practice condition. More recently, eye tracking studies have lent support to this theory,finding that when items were distributed they recieved more attentional processing than the massed items [@koval2019]. Futhermore, this attention was a significant mediator of the efficay of spacing. This theory differs from the others as it focuses on the disadvantages of massed practice more than the advantages of spacing and therefore some have argued it is not a true spacing effect theory [@delaney2010]. Other researchers do consider it a potential mechanism for the spacing effect, but point out additional weaknesses such as its inability to explain why increasing the gap between spacing sessions produces a greater effect [@benjamin2010]. Overall, there is evidence that deficient processing may affect the efficacy of ditributed practice, however, there is little evidence to support a claim that deficient processing is the sole mechanism for the spacing effect.

Recently, as an offshoot of cognitive load theory literature [@sweller1988], ** has been offered as an alternative theory [@chen2018, @chen2019]. They suggest that during massed practice working memory resources are depleted which leads to reduced performance. While in the spaced condition, participants have the opportunity to rest and restore working memory resources. Importantly, they believe this only works when the material is high in element interactivity. When it is low in element interactivity they do not find any Working memory depeletion. Across four experiments, @chen2024, investigate how *element interactivity* affects working memory resource depletion and the spacing effect. Their first experiment establishes that material high in element interactivity (a connected passage of text) depletes working memory resources, while low element interactivity tasks do not (disconntected sentences). Next they show that for low element interactivity material you can find a spacing effect without any working memory resource depletion. This shows that working memory depletion cannot account for all spacing, they suggest that in this case spacing allows for additional rehearsal during rest, which causes the spacing effect. Finally, in the third and fourth experiments participants learnt the product rule in calculus, using worked examples. The key difference between the two experiments was that in the first, the participants were adults who have never learnt calculus before, while in the fourth group they were sixth form students who had a solid foundation in calculus, but had not learnt this specific rule.They hypothesized that the material would be high element  interactivity for the novices and low element interactivity for the more experienced learners. They found a significant spacing and working memory resource depletion effect for the novices, but neither effect for the more experienced learners. These results highlight the important link between prior knowledge, element interactivity and the spacing effect. However, like the deficient processing account a key weakness is their inability to explain why increasing inter-session intervals can boost the efficacy of spacing up to a certain point before elvelling off. The rest periods in @chen2024 are very short (five minutes) if that is sufficent to restore working memory resouirrces tyhen it cannot explain the relationship between inter-session intervals and performance on the post-test.

Numerous models based on the above theories have been created. One experiment compared three computational models, each trained on 14 previous spacing experiment datasets with a combined sample of 2979 participants @walsh2018 . The first model, introduced by the authors, is the Predictive Performance Equation (PPE), which focuses on exponential decay of memories, but adds in a function to allow prior repetitions of the item to reduce the decay rate, which is in line with the study-phase retrieval hypothesis \[\@hintzman1973\]. The second model, first introduced by @pavlik2005, was an extension of ACT-R cognitive architecture, where repetition of a chunk in memory increases its activation, thus making it easier to retrieve. This activation level then decays over time, to represent forgetting. This model is mechanically similar to the PPE, and can be considered another formal model of study-phase retrieval. However the final model, the Search of Associative Memory [@raaijmakers2003], combines deficient processing and contextual variability to create a formal model of the spacing effect. The Predictive Performance Equation and Pavlik and Anderson’s model performed similarly in predicting the results, while the Search of Associative Memory model performed worse. This provides some evidence for study-phase retrieval and against deficient processing and contextual variability. Overall there is greatest evidence for study-phase retrieval, possibly in combination with contextual variability.

# Testing effect and retrieval practice

Retrieval practice is an intervention which harnesses the testing effect. It describes the increase in retention when a to be learned item is actively retrieved from memory as opposed to when it is restudied. Typical retrieval practice paradigms involve an initial learning session followed by a post test. This initial learning session will either be a retrieval or non-retrieval based learning task (see figure 3). In a classic retrieval practice study participants read science facts initially and then either reread the facts or practised retrieval through free recall [@roediger2006]. The rereading group performed significantly better on a 5-minute delayed test, however the results reversed on a 1-week post-test. One large meta analysis containing 159 studies found a medium weighted mean effect size for the testing effect of g = 0.50 (CI \[0.42, 0.58\]), similarly recent meta-analysis looking at the testing effect in the classroom found a effect size (g = 0.499)[@yang2021]. To illustrate what an g = 0.5 effect means, if a study which claimed to raise IQ (where the mean is 100 and standard deviation is 15) and the control and intervention groups both have equal variances, then a 0.5 effect size would mean a 7.5 point increase in IQ.

Figure 3 Simple testing paradigm A picture containing text, screenshot, font, line

Description automatically generated Note. A simple testing paradigm only changes the type of task used after the initial learning session. A retrieval task is compared to a non-retrieval (review) task.

# Theories of the testing effect

There are many theories of the spacing effect [@rowland2014], but this section will focus on the *retrieval effort hypothesis* (coupled with dual memory theory), the *elaborative retrieval hypothesis*, *transfer-appropriate processing* and the *episodic context account*. Firstly, the theory sometimes called the retrieval effort hypothesis (also used within the explanations for the spacing effect) suggests that the additional effort required by a more difficult, yet successful, retrieval leads to the testing effect [@pyc2009]. The mechanism in which increased effort leads to increased retrieval is expanded upon by the dual memory theory [@rickard2018]. Mechanically, it is almost identical to study-phase retrieval (see section 1.1). They propose that initial learning is encoded in the study phase and subsequent retrieval (with feedback) strengthens the original memory and encodes the test memory. This increases future chances of retrieval in the test condition as the initial or test memory can be retrieved, while in the study condition, only the initial memory can be retrieved. They suggest the additional effort required from retrieval is due to having to encode a new test memory alongside retrieval of the study memory. They formally modelled their theory and tested it against the datasets from experiments in their lab and they extracted 114 testing effects from the literature. The model predicts an envelope, an upper and lower bound, they suspect will contain the magnitude of the testing effect. This envelope captures a third of the range of logical potential testing effects. Of the 144 testing effects, their model’s bounds overlapped with the true magnitude of the effect (within the confidence interval) in all but five cases. This provides quantitative evidence for this theory, though their prediction envelope is quite large.

Secondly, the elaborative retrieval hypothesis suggests that the benefit of testing comes from the activation of the target alongside other memories creating an elaborative semantic network increasing the number of pathways that future retrievals can access [@carpenter2009]. In one experiment, participants learnt word pairs. These pairings were either strongly associated(Toast - Bread) or weakly associated (Basket - Bread)[@carpenter2009]. They hypothesised that if elaborative retrieval was the mechanism which underlies the testing effect then items with weak associations will be harder to recall initially, but they will create stronger elaborative routes making final recall better than items with strong associations. They found significant results to support this hypothesis.

Thirdly, transfer-appropriate processing, suggests that retention on the final test benefits from the amount of overlap a retrieval event has with the final test [@morris1977levels; @blaxton1989]. However, an experiment designed to evaluate transfer-appropriate processing against the elaborative retrieval hypothesis found little evidence for transfer-appropriate processing [@carpenter2006impoverished]. In this experiment participants were asked to recall a list of words and the type of retrieval in the training and final test conditions were either the same or were mismatched (i.e., free recall during training then free recall in the final test or multiple choice then free recall). This suggests that similarity of the type of test during retrieval does not reflect the retention on a post-test of the same or different type, while transfer-appropriate processing would predict that to be the case.

Finally, the episodic context account. @karpicke2014 outline four assumptions used to create the episodic context account: Firstly, people encode information about the item’s temporal context during encoding. Secondly, using any potential cues participants reconstruct the past episodic memory. Thirdly, each retrieval updates the prior representation in long-term memory. Finally, this updated representation allows the subject to limit their search of cues to only the most useful ones. The benefit of testing comes from the updated representation limiting the search to only the features that will help future recall. Support for the episodic context account can be found when participants are asked to make judgements about when they initially studied an item [@whiffen2017]. In the experiment participants learnt a list of words, then either restudied them or were asked to make a judgement about when they studied the word. The authors hypothesised that making the judgement would cause participants to retrieve the original context of when they studied the word. Later on a free recall task, participants who made the temporal judgements on the words performed significantly better. This supports the episodic context account.

# Spaced retrieval practice

Rather than discussing mathematics learning within the spacing or testing literature in isolation, it may be better to consider them both here as it is often difficult to be sure whether students were required to retrieve the information (see below for details). Furthermore, there is evidence that spaced retrieval can greatly increase learning. One recent meta-analysis found a large overall effect ( g =1.01, 95% CI \[0.68, 1.34\]), which when corrected for bias within the literature was still notable (g = 0.74, 95% CI \[0.55, 0.91\]) [@latimier2021]. This section will first briefly cover how experiments of the testing effect with mathematical content can be designed. Then I will discuss potential pitfalls surrounding retrieval in experiments with mathematical content and what typical paradigms for spaced retrieval practice look like in the domain of mathematics learning. Finally, this section will finish with a review of potential moderators of spaced retrieval practice.

## Retrieval in mathematics

There is limited evidence specific to the domain of mathematics for the testing effect with no spacing. An exception is a well-designed study by @fazio2018 comparing retrieval practice with worked example problem pairs. In the retrieval condition they were tested on the procedure, but in the worked example condition they were presented with a worked example they could follow along with, so they may not have had to retrieve the procedure. They found that worked examples increased performance on an immediate test, but the retrieval condition produced greater retention on a delayed test. Some spacing experiments found that it only increased the performance of medium performers [@nazari2019]. One reason, not discussed by the authors, may be that for many experiments involving mathematics material it is difficult to know whether pupils actually had to retrieve the material or whether they could potentially have used the resources provided to mitigate the need to retrieve in the “practice” conditions. Here are two examples where authors are specific about what participants had access to: "While working on the practice sheets, each student had access to a summary sheet containing examples, including solutions, from the introductory lesson." [@nazari2019, 2019, pg. 291] and “Throughout each practice session, students could see their written work for practice problems that had appeared previously in the session.” [@emeny2021; pg. 1085]. In both cases it is plausible that participants who were struggling looked back at their previous work, not having to retrieve the information and effectively restudying the problem, possibly negating the spacing effect. This may make (spaced) retrieval practice in mathematics most useful for learners who grasped the topic enough to at least attempt to retrieve the procedure or concept before looking back at previous work and examples. This provides increased benefit as, even if they are unable to successfully retrieve the procedure, prior research has found that even incorrect retrievals can improve future retrieval [@potts2019]. Indeed, exploratory analyses of an experiment that failed to find an overall spacing effect have found that distributed practice may be more effective for students of medium performance level [@nazari2019]. They suggest their results were due to low performers not managing to grasp the idea while the high-performance group was immediately at ceiling and therefore the practice condition had no visible effect. The need to ensure adequate practice for low performers and then force retrieval within retrieval and spaced retrieval experiments is important, as it may account for the experiments where no effect was found for those groups [@nazari2019].

## Typical paradigms in mathematics spaced (retrieval) experiments

The literature which underpins this project falls broadly into three possible categories, pure spacing, pure retrieval practice, and spaced retrieval practice. Firstly, it is important to highlight a major difference between other domains and Mathematics. It is much more common to see across-session designs [@küpper-tetzel2014]. Across-session spacing (and spaced retrieval) experiments typically either focus on applying spacing and retrieval to one or two procedures and vary the inter-session interval and retrieval interval [@rohrer2006; @rohrer2007], or they apply the techniques to a cohort in a course, where the retrieval interval may differ for items presented at the start of the course and those at the end [@lyle2020; @bego2017; @crissinger2015]. While lacking ecological validity, the isolated inter-session interval orretrieval interval experiments (see figure 2) provide a purer measurement of the spacing effect than within course experiments. This is because as rearranging the material during the course inevitably leads to interleaving effects as well. Previous studies have attempted to isolate the spacing effect and interleaving effect. This is important as while all interleaving is subject to spacing, there is also an additional benefit to participants’ ability to discriminate between problems [@chen2021].

Early studies showed the important relationship between retrieval interval and inter-session interval and that the benefits of spacing are typically observed over longer periods of time and can often be detrimental to immediate performance. For example, participants either massed ten combinatorics problems in one session or spaced them across two sessions with an inter-session interval of one week [@rohrer2006]. After one week, when tested, there was no significant effect of spacing, but there was a substantial large effect when tested four weeks later. However, in a similar experiment, one week was sufficient to see a large spacing effect [@rohrer2007].

A second type of experimental design incorporates spaced retrieval practice into courses through cumulative testing. A common example would be to take a course currently running over a semester in a university and add weekly tests. For example, in @hopkins2016 the massed condition contained novel questions about that week's topic, while in the spaced condition there are typically some novel questions from the current topic, but the test will also consist of topics previously covered within the course. One reason this is good is that it is ecologically valid and easy to apply. On the other hand, it is more difficult to measure the specific effect of spacing on particular topics as items nearer the beginning may have a larger retrieval interval than those presented later. Furthermore, it is not possible to space materials learnt just before the exam. However, some have attempted to solve this problem by excluding topics learnt near the end of the course from their analyses [@hopkins2016; @lyle2020]. Another potentially confounding factor is that simpler concepts presented at the start of the course may be used as building blocks for the later topics, which would mean these concepts get additional testing. Additionally, within this type of experimental design it is often difficult to see exactly how the individual items are spaced and how specifically they report the schedule varies from paper to paper. For example, some are very vague where they say they change five to ten percent of any homework assignment between the standard all novel homework versus the cumulative condition [@beagley2020].

## Moderators of the Efficacy of Spaced Retrieval Practice

Other than the inter-session interval and retrieval interval mentioned earlier other factors are thought to modulate the efficacy of spaced retrieval. Individual differences may play a part in the efficacy of the spacing effect and learners’ ability to implement a distributed practice routine. When students signed up for optional additional practice sessions for statistics, those in the distributed practice condition had a much higher rate of attrition than those on the massed practice schedule [@nazari2019]. They also found that female students had a significantly higher chance of completing the practice sessions. However, that analysis was performed exploratorily, and additional confirmatory work is required to evidence their claims. As this was optional extra practice, this could have affected their study in two directions. First they may have biassed their work towards those who want to work hard and have high conscientiousness. However they may have also biassed the sample in the other direction, perhaps those who understood it all well didn’t think they needed more practice, or parental pressure to sign up may have meant that only those who were already struggling in mathematics signed up. Complexity has previously been looked at in spacing and testing effect literature. A previous meta-analysis coded studies by overall complexity which “was defined by the degree to which the task requires a number of distinct behaviours, the number of choices involved in the performance of the task, and the degree of uncertainty involved in performance of the task” [@donovan1999]. They found that overall complexity of the material was correlated with lower effect sizes. This definition is underspecified and does not provide a concrete measure of complexity but does suggest complexity may be an important moderator.

# Complexity in Mathematics

Complexity has been chosen as the first moderator of the spacing effect to investigate for three reasons. Firstly, as @donovan1999 found that it was a significant moderator of the spacing effect in their meta-analysis. Secondly, the literature review undertaken so far has not found any studies that systematically investigate complexity and spacing. And finally, if complexity is a mediating factor then it may be easy to adjust algorithms or individualised learning systems that employ a spaced retrieval schedule, allowing the results of any research to have an immediate positive impact.

## Defining complexity

Complexity is often defined procedurally or conceptually [@crooks2014]. Previous reviews of the literature surrounding mathematical complexity of material suggest that experiments that claim to measure conceptual complexity are often ill defined and not operationalized in theoretically relevant ways, finding that only 35% of the studies defined conceptual knowledge [@crooks2014]. Due to the lack of consensus on defining and operationalising conceptual complexity this project will focus on procedural complexity. While higher-level conceptual knowledge is important, basic procedural facts are still vital for students to gain proficiency in. For example, being able to quickly retrieve a procedure or basic fact is very useful when solving more complex problems [@roediger2012]. Additionally, a procedure can be taught in isolation, while conceptual knowledge, which requires links between topics by definition, cannot [@hiebert1986procedural]. This enables the selection of material, which requires few prerequisites and is novel to the participants, which is useful experimentally. Within mathematics education procedural knowledge is thought of as the knowledge of the steps of how to solve a particular problem. It is commonly measured by tracking participants' accuracy on problem solving tasks [@crooks2014]. Others further refine procedural knowledge in mathematics by separating out knowledge of the form, the formal language and symbols used to communicate mathematics, from knowledge of the rules, procedures, and algorithms to solve specific tasks [@hiebert1986procedural]. This is a very useful distinction as it is important to ensure that the form of the mathematics does not impede participants ability to learn and retrieve the rule. For example, one spacing experiment left out the factorial symbol “!” when teaching participants a procedure [@rohrer2007]. This is an example of prioritising the algorithm required to solve the specific problem, while reducing the complexity of the form the problem is presented in.

A recent proposal, which was published after our first round of experiments were underway suggested that task complexity should be measures using *element interactivity*. In cognitive load theory literature, element interactivi

## Complexity and spacing

Several theories of the spacing effect may be affected by complexity. The study-phase retrieval account, for example, could predict the effects of spacing would increase, decrease, or disappear entirely, depending on the experimental design. To illustrate this, imagine a hypothetical experiment where low or high complexity material is either spaced or massed. If the spacing condition was equal across complexity conditions, the experimenter could choose to either optimise the spacing of the low or high complexity material. The “optimal” inter-session intervals for low complexity material would mean they were retrieved just before they were forgotten [@cepeda2006], as this would require the most effort to retrieve them while still successful resulting in the biggest boost to retrieval strength [@bjork2011]. Assuming that more complex material is more difficult to retrieve given an equivalent amount of practice, then this inter-session interval would be sub-optimal for the more complex material, as many participants would not successfully retrieve the prior learning event, and participants would perform worse on a post-test. If instead the experiment was designed to optimise the spacing of the more complex material then the lower complexity material would be retrieved more easily, requiring less effort, and therefore reducing the spacing effect.

It is difficult to predict whether contextual variability would be affected by the complexity of the material, as this theory relies on picking up contextual information around the learning session to provide future paths for retrieval. Perhaps if maximum attention is required to learn an item then there is less opportunity to pick up other contextual cues.

The deficient processing theory may predict that low complexity material would be glanced over and not given sufficient processing therefore weakening the effect of spacing. Alternatively, more complex material may have sufficient time to be processed in the massed condition, but insufficient time to process in the spaced condition. This would predict that the relationship between complexity and spacing would be highly dependent on the scheduling conditions. If complexity reduces the efficacy of the spacing effect then subsequent experiments could aim to find ways around this. If the spacing effect relies on successful retrieval, complexity may reduce the efficacy of spacing by reducing the chance of successful retrieval. In this case shorter inter-session intervals may improve retention, as this will decrease the difficulty of retrieval.

## Current project

This literature review defined spacing and retrieval, and looked at the factors that moderate the efficacy of spaced retrieval practice. Complexity appears to be an important moderator due to past meta-analyses [@donovan1999], the lack of any studies that systematically investigate complexity and the ease in which it could be used to improve current spaced repetition algorithms. Therefore, initially this project will look at the following research questions and investigate these hypotheses: Research questions: 1. Does spaced retrieval practice work for mathematics learning? 2. Does the procedural complexity of the material affect the efficacy of spaced retrieval practice? 3. How does the procedural complexity of the material affect the efficacy of spaced retrieval practice? Hypotheses: 1. Spaced retrieval practice increases retention of mathematics learning. 2. Spacing schedules that are best for lower complexity material will not benefit higher complexity material 3. Decreasing the inter-session interval will make spacing schedules more effective for higher complexity material Planned studies: \* Meta-analysis: \* A meta-analytic review of the effectiveness of spacing and retrieval for the retention of mathematics. \* Will aim to address RQ 1 and look for variables that moderate spaced retrieval. \* Experiment 1 \* A two (spaced or massed practice) between by two (low or high complexity) within subjects design aimed to answer RQ 2. \* Experiment 2 \* A two (spaced/ massed practice) between by two (shorter longer interval) between by two (low/ high complexity) within subjects design aimed to answer RQ 3. \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_

# References

<!-- References will auto-populate in the refs div below -->

::: {#refs}
:::
